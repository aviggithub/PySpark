# PySpark  PySpark tutorial
PySpark is a Python API for support Python with Spark. Whether it is to perform computations on large datasets or to just analyze them


### Key Features of PySpark
#### Real-time computations: 
Because of the in-memory processing in the PySpark framework, it shows low latency.
#### Polyglot: 
The PySpark framework is compatible with various languages such as Scala, Java, Python, and R, which makes it one of the most preferable frameworks for processing huge datasets.
#### Caching and disk persistence: 
This framework provides powerful caching and great disk persistence.
#### Fast processing: 
The PySpark framework is way faster than other traditional frameworks for Big Data processing.
#### Works well with RDDs: 
Python programming language is dynamically typed, which helps when working with RDDs.

## Install pySpark 
pip install pyspark
